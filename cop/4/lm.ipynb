{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://sct.inf.utfsm.cl/wp-content/uploads/2020/04/logo_di.png\" style=\"width:60%\">\n",
    "\n",
    "<center>\n",
    "    <h1>ILI285/INF285 Computación Científica </h1>\n",
    "    <h1> COP-4</h1>\n",
    "    <h1> LM: Levenberg-Marquardt</h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere el siguiente conjunto de datos $D=\\{(x_1,y_1),(x_2,y_2), \\dots, (x_n, y_n)\\}$ que se quieren ajustar con la siguiente función $f(x, \\boldsymbol{\\beta})=\\beta_1+\\sin(\\beta_2\\,x)+\\cos(\\beta_3\\,x)$, donde $\\boldsymbol{\\beta}=(\\beta_1, \\beta_2, \\beta_3 )$.  Para esto requerimos minimizar la función $S(\\boldsymbol{\\beta})=\\displaystyle \\sum_{i=1}^n \\left(y_i- f(x_i, \\boldsymbol{\\beta})\\right)^{\\{2, 4\\}}$. De similar forma a lo realizado en el certamen anterior, debemos encontrar un mínimo, para lo cual debemos obtener las derivadas parciales con respecto a los parámetros, esto es:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        \\frac{\\partial S}{\\partial \\beta_1} &= \n",
    "        \\sum_{i=1}^n -\\{2, 4\\}(y_i-\\beta_1-\\sin(\\beta_2\\,x_i)-\\cos(\\beta_3\\,x_i))^{\\{1, 3\\}} = 0 \\\\\n",
    "        \\frac{\\partial S}{\\partial \\beta_2} &= \n",
    "        \\sum_{i=1}^n -\\{2, 4\\}x_i\\cos(\\beta_2\\,x_i)(y_i-\\beta_1-\\sin(\\beta_2\\,x_i)-\\cos(\\beta_3\\,x_i))^{\\{1, 3\\}} = 0 \\\\\n",
    "        \\frac{\\partial S}{\\partial \\beta_3} &= \n",
    "        \\sum_{i=1}^n \\{2, 4\\}x_i\\sin(\\beta_3\\,x_i)(y_i-\\beta_1-\\sin(\\beta_2\\,x_i)-\\cos(\\beta_3\\,x_i))^{\\{1, 3\\}} = 0 \n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Podemos llevar la expresión anterior al problema $\\mathbf{F}(\\boldsymbol{\\beta})=\\mathbf{0}$, donde $\\mathbf{F}(\\boldsymbol{\\beta})$ se define como:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbf{F}(\\boldsymbol{\\beta}) = \n",
    "    \\begin{bmatrix}\n",
    "        \\displaystyle \\sum_{i=1}^n(y_i-\\beta_1-\\sin(\\beta_2\\,x_i)-\\cos(\\beta_3\\,x_i))^{\\{1, 3\\}} \\\\\n",
    "        \\displaystyle \\sum_{i=1}^nx_i\\cos(\\beta_2\\,x_i)\\,(y_i-\\beta_1-\\sin(\\beta_2\\,x_i)-\\cos(\\beta_3\\,x_i))^{\\{1, 3\\}} \\\\\n",
    "        \\displaystyle \\sum_{i=1}^nx_i\\sin(\\beta_3\\,x_i)\\,(y_i-\\beta_1-\\sin(\\beta_2\\,x_i)-\\cos(\\beta_3\\,x_i))^{\\{1, 3\\}}\n",
    "    \\end{bmatrix}. \\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Para obtener el $\\boldsymbol{\\beta}$ que minimiza $S$, utilizaremos una variante del método de Newton en alta dimensión, el cual es conocido como el método de Levenberg-Marquardt. En resumen, este método es muy similar al método de Newton en $\\mathbb{R}^n$ pero el sistema de ecuaciones que se resuelve en cada iteración es el siguiente:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        \\left(J(\\boldsymbol{\\beta}_i)^TJ(\\boldsymbol{\\beta}_i) + \n",
    "        \\lambda\\,I\\right) \\Delta \\boldsymbol{\\beta}_i\n",
    "        & = -J(\\boldsymbol{\\beta}_i)^T\\mathbf{F}(\\boldsymbol{\\beta}_i),\\\\\n",
    "        \\boldsymbol{\\beta}_{i+1}&=\\boldsymbol{\\beta}_i+\\Delta \\boldsymbol{\\beta}_i\n",
    "    \\end{split}\\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "donde $J(\\boldsymbol{\\beta}_i)$ es la matriz Jacobiana de $\\mathbf{F}$ evaluada en $\\boldsymbol{\\beta}_i$. El objetivo del parámetro $\\lambda$ es reducir el número de condición asociado a la matriz $J(\\boldsymbol{\\beta}_i)^T\\,J(\\boldsymbol{\\beta}_i)$, además de mejorar la convergencia del método. Sin embargo, al utilizar un valor de $\\lambda$ muy grande, la solución obtenida es una perturbación de la solución límite, es decir, cuando $\\lambda$ tiende a $0$.  Para evitar calcular la matriz Jacobiana $J(\\boldsymbol{\\beta})$ utilizaremos una aproximación. Considere la siguiente linealización de la función $\\mathbf{F}$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{F}(\\boldsymbol{\\beta} + \\varepsilon\\,\\mathbf{v}) = \\mathbf{F}(\\boldsymbol{\\beta}) + \n",
    "J(\\boldsymbol{\\beta})(\\varepsilon\\,\\mathbf{v}) + \\text{Términos de orden } \\varepsilon^2 + \\dots.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "donde $\\mathbf{v}$ es un vector que será definido más adelante y $0 <\\varepsilon \\ll 1$ un escalar.  Basado en la expansión anterior, podemos despejar el producto de la matriz Jacobiana por el vector $\\mathbf{v}$ de la siguiente forma:\n",
    "\n",
    "\\begin{equation}\n",
    "    J(\\boldsymbol{\\beta})\\,\\mathbf{v} \\approx\n",
    "    \\frac{\\mathbf{F}(\\boldsymbol{\\beta} + \\varepsilon\\,\\mathbf{v}) \n",
    "    - \\mathbf{F}(\\boldsymbol{\\beta})}{\\varepsilon}\\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Con esta aproximación, podemos notar que al definir $\\mathbf{v}=\\mathbf{e}_1=[1,0,0]^T$, se obtiene una aproximación de la primera columna de $J(\\boldsymbol{\\beta})$, con $\\mathbf{v}=\\mathbf{e}_2=[0,1,0]^T$ la segunda columna y $\\mathbf{v}=\\mathbf{e}_3=[0,0,1]^T$ la tercera columna. Dicho de otra manera, tenemos:\n",
    "\n",
    "\\begin{equation}\n",
    "    J(\\boldsymbol{\\beta}) \\approx\n",
    "    \\left[\n",
    "        \\begin{array}{c|c|c}\n",
    "            & & \\\\\n",
    "            \\frac{\\mathbf{F}(\\boldsymbol{\\beta} + \\varepsilon\\,\\mathbf{e}_1) \n",
    "            - \\mathbf{F}(\\boldsymbol{\\beta})}{\\varepsilon} & \n",
    "            \\frac{\\mathbf{F}(\\boldsymbol{\\beta} + \\varepsilon\\,\\mathbf{e}_2) \n",
    "            - \\mathbf{F}(\\boldsymbol{\\beta})}{\\varepsilon} & \n",
    "            \\frac{\\mathbf{F}(\\boldsymbol{\\beta} + \\varepsilon\\,\\mathbf{e}_3) \n",
    "            - \\mathbf{F}(\\boldsymbol{\\beta})}{\\varepsilon} \\\\\n",
    "            & &\n",
    "        \\end{array}\n",
    "    \\right]\n",
    "\\end{equation}\n",
    "\n",
    " \n",
    "\n",
    "La gran ventaja de la aproximación anterior es que uno puede obtener numéricamente una estimación razonable de la matriz Jacobiana omitiendo el manejo algebraico de obtener el gradiente de cada termino en la ecuación $(1)$.\n",
    "\n",
    "Considerando el cálculo de la matriz Jacobiana aproximada por la ecuación $(3)$ con $\\varepsilon=10^{-10}$ y la iteración de Levenberg-Marquardt definida en $(2)$, determine el valor del parámetro $\\beta_1$ luego de $\\{3,4,5\\}$ iteraciones del método de Levenberg-Marquardt utilizando $\\lambda = 1$ y para resolver el sistema de ecuaciones en $(2)$, utilice al algoritmo de {Jacobi, Gauss-Seidel, SOR($1.1$)} con $3$ iteraciones, *initial guess* $\\boldsymbol{\\beta}_0=[1,1,1]^T$ y $10^{-10}$ como tolerancia en {Jacobi, Gauss-Seidel, SOR($1.1$)}.\n",
    "\n",
    "Los datos para ajustar el modelo se encuentran en https://github.com/sct-utfsm/INF-285/tree/master/cop-4/data/lm/1.npy. En la primera columna encontrará los valores de $x_i$ y la segunda columna los valores de $y_i$.\n",
    "\n",
    "**Debe entregar sus resultados con 5 decimales sin redondear. Por ejemplo si su resultado es 2365.1345871237 debe completar con 2365.13458.**\n",
    "\n",
    "**Preguntas:**\n",
    "\n",
    "1. **[6 puntos]** ¿Cuál es el valor de la segunda componente de $\\mathbf{F}(\\boldsymbol{\\beta}_0)$? \n",
    "2. **[10 puntos]** ¿Cuál es la norma de Frobenius de la aproximación del Jacobiano en $\\boldsymbol{\\beta}_0$, es decir,  $\\|J(\\boldsymbol{\\beta}_0)\\|_F$? \n",
    "3. **[24 puntos]** ¿Cuál es el valor del parámetro $\\beta_1$ luego de ajustar el modelo? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as spla\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Solvers* de sistemas de ecuaciones lineales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi(A, b, x_0=None, max_iter=50, tol=1e-10):\n",
    "    n = A.shape[0] # Matrix size\n",
    "    X = np.zeros((max_iter + 1, n)) # Matrix with solution at each iteration\n",
    "    # Initial guess\n",
    "    if x_0 is not None:\n",
    "        X[0] = x_0\n",
    "    D = np.diag(A) # Diagonal of A (only keep a vector with diagonal)\n",
    "    D_inv = np.diag(1 / D) # Inverse of D\n",
    "    r = b - np.dot(A, X[0]) # Residual vector\n",
    "    # Jacobi iteration\n",
    "    for k in range(max_iter):\n",
    "        X[k+1] = X[k] + np.dot(D_inv, r)\n",
    "        r = b - np.dot(A, X[k+1]) # Update residual\n",
    "        if np.linalg.norm(r) < tol: # Stop criteria\n",
    "            X = X[:k+2]\n",
    "            break\n",
    "    return X[-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussSeidel(A, b, x_0=None, max_iter=50, tol=1e-10):\n",
    "    n = A.shape[0] # Matrix size\n",
    "    X = np.zeros((max_iter + 1, n)) # Matrix with solution at each iteration\n",
    "    # Initial guess\n",
    "    if x_0 is not None:\n",
    "        X[0] = x_0\n",
    "    LD = np.tril(A) # Get lower triangle (L + D)\n",
    "    # Get inverse in O(n^2) instead of np.linalg.inv(LD) O(n^3)\n",
    "    LD_inv = spla.solve_triangular(LD, np.eye(n), lower=True) \n",
    "    r = b - np.dot(A, X[0]) # Residual\n",
    "    # Gauss-Seidel iteration\n",
    "    for k in range(max_iter):\n",
    "        X[k+1] = X[k] + np.dot(LD_inv, r)\n",
    "        r = b - np.dot(A, X[k+1]) # Residual update\n",
    "        if np.linalg.norm(r) < tol: # Stop criteria\n",
    "            X = X[:k+2]\n",
    "            break\n",
    "    return X[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SOR(A, b, x_0=None, w=1.05, max_iter=50, tol=1e-10):\n",
    "    n = A.shape[0] # Matrix size\n",
    "    X = np.zeros((max_iter + 1, n)) # Matrix with solution at each iteration\n",
    "    # Initial guess\n",
    "    if x_0 is not None:\n",
    "        X[0] = x_0\n",
    "    L = np.tril(A, k=-1) # Get lower triangle \n",
    "    Dw = np.diag(np.diag(A) / w)\n",
    "    # Get inverse in O(n^2) instead of np.linalg.inv(L+Dw) O(n^3)\n",
    "    LDw_inv = spla.solve_triangular(L + Dw, np.eye(n), lower=True) \n",
    "    r = b - np.dot(A, X[0]) # Residual\n",
    "    # SOR iteration\n",
    "    for k in range(max_iter):\n",
    "        X[k+1] = X[k] + np.dot(LDw_inv, r)\n",
    "        r = b - np.dot(A, X[k+1]) # Residual update\n",
    "        if np.linalg.norm(r) < tol: # Stop criteria\n",
    "            X = X[:k+2]\n",
    "            break\n",
    "    return X[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levenberg-Marquardt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenbergMarquardt(F, J, x_0, l, solver, max_iter=100, tol=1e-10):\n",
    "    x = np.zeros((max_iter + 1, x_0.shape[0]))\n",
    "    x[0] = x_0\n",
    "    for k in range(max_iter):\n",
    "        JT = J(x[k]).T # Compute transpose of J\n",
    "        JTJ = np.dot(JT, J(x[k]))  # Compute J.T J\n",
    "        JTJ_l = JTJ + l * np.eye(x_0.shape[0])  # J.T J + \\lambda I\n",
    "        JTF = np.dot(JT, F(x[k])) \n",
    "        w = solver(JTJ_l, -JTF)\n",
    "        x[k+1] = x[k] + w\n",
    "        if np.linalg.norm(F(x[k+1])) < tol:\n",
    "            x = x[:k+2]\n",
    "            break\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x, beta: beta[0] + np.sin(beta[1] * x) + np.cos(beta[2] * x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FD(F, x, v, eps=1e-10):\n",
    "    return (F(x + eps * v) - F(x)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildFJ(x_i, y_i, f_opt):\n",
    "    f1 = f_opt['f1']\n",
    "    f2 = f_opt['f2']\n",
    "    f3 = f_opt['f3']\n",
    "    F = lambda beta: np.array([f1(beta), f2(beta), f3(beta)])\n",
    "    I = np.eye(3)\n",
    "    J = lambda beta: np.array([\n",
    "        FD(F, beta, I[0]), FD(F, beta, I[1]), FD(F,beta, I[2])\n",
    "    ]).T\n",
    "    return F, J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data/lm/1.npy')\n",
    "x_i, y_i = data[:, 0], data[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(Sopt, sol, lam, solv_iter, lm_iter, lm_b0, sol_x0, plo, verb=0):\n",
    "    if lm_b0 == sol_x0 == 0:\n",
    "        print(\"Opcion no valida\")\n",
    "        return None\n",
    "    \n",
    "    b0 = np.ones(3) * lm_b0\n",
    "    x0 = np.ones(3) * sol_x0\n",
    "    if Sopt == 0:\n",
    "        f_S = {\n",
    "            'f1': lambda beta: np.sum(y_i - f(x_i, beta)),\n",
    "            'f2': lambda beta: np.sum(x_i * np.cos(beta[1] * x_i) * (y_i - f(x_i, beta))),\n",
    "            'f3': lambda beta: np.sum(x_i * np.sin(beta[2] * x_i) * (y_i - f(x_i, beta)))\n",
    "        }\n",
    "    elif Sopt == 1:\n",
    "        f_S = {\n",
    "            'f1': lambda beta: np.sum((y_i - f(x_i, beta)) ** 3),\n",
    "            'f2': lambda beta: np.sum(x_i * np.cos(beta[1] * x_i) * (y_i - f(x_i, beta)) ** 3),\n",
    "            'f3': lambda beta: np.sum(x_i * np.sin(beta[2] * x_i) * (y_i - f(x_i, beta)) ** 3)\n",
    "        }\n",
    "        \n",
    "    F, J = buildFJ(x_i, y_i, f_S)\n",
    "    \n",
    "    F_b0 = F(b0)\n",
    "    J_b0 = J(b0)\n",
    "    \n",
    "    if verb:\n",
    "        print(\"Respuestas: \")\n",
    "        print(\"--------------------\")\n",
    "        print(\"1. Segunda componente de F(\\\\vec{beta}_0): %.6f\" %  F_b0[1])\n",
    "        print(\"2. ||J(\\\\vec{beta}_0)||_F: %.6f\" % np.linalg.norm(J_b0, ord=\"fro\"))\n",
    "\n",
    "    ss = [jacobi, gaussSeidel, SOR]\n",
    "    \n",
    "    if sol < 2:\n",
    "        solver = lambda A, b: ss[sol](A, b, max_iter=solv_iter, x_0=x0) \n",
    "    elif sol == 2:\n",
    "        solver = lambda A, b: ss[sol](A, b, max_iter=solv_iter, w=1.1, x_0=x0) \n",
    "        \n",
    "    B = levenbergMarquardt(F, J, b0, lam, solver, lm_iter, tol=1e-10)\n",
    "    \n",
    "    if verb:\n",
    "        print(\"3. beta_1 luego de %d iteraciones: %.6f\" %(lm_iter, B[-1, 0]))\n",
    "    if plo:\n",
    "        plt.plot(x_i, y_i, 'r.')\n",
    "        plt.plot(x_i, f(x_i, B[-1]), '--', label='Curve')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(r'$x$')\n",
    "        plt.ylabel(r'$y$')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Respuestas\n",
    "\n",
    "Se considera el uso de:\n",
    "* $\\boldsymbol{\\beta}_0=[1,1,1]$ como *initial guess* tanto para Levenberg-Marquard como para el *Solver* iterativo.\n",
    "* $\\boldsymbol{\\beta}_0=[1,1,1]$ como *initial guess* de Levenberg-Marquard y $[0,0,0]$ como *initial guess*  para el *Solver* iterativo.\n",
    "* $\\boldsymbol{\\beta}_0=[0,0,0]$ como *initial guess* de Levenberg-Marquard y $[1,1,1]$ como *initial guess*  para el *Solver* iterativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# widgets\n",
    "sol = Dropdown(options=[('Jacobi', 0), ('Gauss-Seidel', 1), ('SOR(1.1)', 2)], value=0, description=\"Solver\")\n",
    "Sopt = Dropdown(options=[('S1', 0), ('S2', 1)], value=0, description=\"Función de Error\")\n",
    "lit = Dropdown(options=[3, 4, 5], description=\"Levenberg-Marquardt solver\")\n",
    "lm_b0_ = Dropdown(options=[('[0, 0, 0]', 0), ('[1, 1, 1]', 1)], \n",
    "                  value=1, description=r\"L-M: $\\boldsymbol{\\beta}_0$\")\n",
    "sol_x0_ = Dropdown(options=[('[0, 0, 0]', 0), ('[1, 1, 1]', 1)], \n",
    "                   value=1, description=r\"Solver: $\\boldsymbol{\\beta}_0$\")        \n",
    "plo = Checkbox(\n",
    "    value=False,\n",
    "    description='Plot',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01dfb1f0c8414e6d8b886f19bc69fc2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Función de Error', options=(('S1', 0), ('S2', 1)), value=0), Dropd…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.experiment(Sopt, sol, lam, solv_iter, lm_iter, lm_b0, sol_x0, plo, verb=0)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def onChange1(args):\n",
    "    if args['new'] == 0:\n",
    "        sol_x0_.value = 1\n",
    "        \n",
    "def onChange2(args):\n",
    "    if args['new'] == 0:\n",
    "        lm_b0_.value = 1\n",
    "        \n",
    "lm_b0_.observe(onChange1, 'value')\n",
    "sol_x0_.observe(onChange2, 'value')\n",
    "\n",
    "interact(experiment, Sopt=Sopt, sol=sol, lam=fixed(1), solv_iter=fixed(3), \n",
    "         lm_iter=lit, lm_b0=lm_b0_, sol_x0=sol_x0_, plo=plo, verb=fixed(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
